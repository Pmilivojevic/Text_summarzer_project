{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_path: Path\n",
    "    tokenizer_path: Path\n",
    "    metric_file_name: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textSummarizer.constants import *\n",
    "from textSummarizer.utils.utils import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_file_path=CONFIG_FILE_PATH,\n",
    "            params_file_path=PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_path=config.model_path,\n",
    "            tokenizer_path=config.tokenizer_path,\n",
    "            metric_file_name=config.metric_file_name\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_from_disk, load_metric\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config=ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def generate_batch_sized_chunks(self, list_of_elements, batch_size):\n",
    "        for i in range(0, len(list_of_elements), batch_size):\n",
    "            yield list_of_elements[i: i+batch_size]\n",
    "\n",
    "    def calculate_metric_on_test_ds(\n",
    "        self,\n",
    "        dataset,\n",
    "        metric,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        batch_size=16,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        colum_text=\"article\",\n",
    "        colum_summary=\"highlights\"\n",
    "    ):\n",
    "        article_batches = list(self.generate_batch_sized_chunks(dataset[colum_text], batch_size))\n",
    "        target_batches = list(self.generate_batch_sized_chunks(dataset[colum_summary], batch_size))\n",
    "\n",
    "        for article_batch, target_batch in tqdm(\n",
    "            zip(article_batches, target_batches), total=len(article_batches)\n",
    "        ):\n",
    "            inputs = tokenizer(\n",
    "                article_batch,\n",
    "                max_length=1024,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                return_tensor=\"pt\"\n",
    "            )\n",
    "\n",
    "            summaries = model.generate(\n",
    "                input_ids=inputs['input_ids'].to(device),\n",
    "                attention_mask=inputs['attention_mask'].to(device),\n",
    "                length_penalty=0.8,\n",
    "                num_beams=8,\n",
    "                max_length=128\n",
    "            )\n",
    "\n",
    "            decoded_summaries = [\n",
    "                tokenizer.decode(\n",
    "                    s,\n",
    "                    skip_special_tokens=True,\n",
    "                    clean_up_tokenization_space=True\n",
    "                ) for s in summaries\n",
    "            ]\n",
    "\n",
    "            decoded_summaries = [d.replase(\"\", \" \") for d in decoded_summaries]\n",
    "\n",
    "            metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "        score = metric.compute()\n",
    "\n",
    "        return score\n",
    "    \n",
    "    def evaluate(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_path).to(device)\n",
    "\n",
    "        dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
    "\n",
    "        rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "        rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "        score = self.calculate_metric_on_test_ds(\n",
    "            dataset_samsum_pt['test'][0:10],\n",
    "            rouge_metric,\n",
    "            model_pegasus,\n",
    "            tokenizer,\n",
    "            batch_size=2,\n",
    "            colum_text=\"dialogue\",\n",
    "            colum_summary=\"summary\"\n",
    "        )\n",
    "\n",
    "        rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "\n",
    "        df = pd.DataFrame(rouge_dict, index=['pegasus'])\n",
    "        df.to_csv(self.config.metric_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-10 00:03:26,021: INFO: utils: yaml file config/config.yaml loaded successfully:]\n",
      "[2024-02-10 00:03:26,025: INFO: utils: yaml file params.yaml loaded successfully:]\n",
      "[2024-02-10 00:03:26,026: INFO: utils: created directory at: artifacts:]\n",
      "[2024-02-10 00:03:26,027: INFO: utils: created directory at: artifacts/model_evaluation:]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: 'artifacts/model_trainer/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/env/lib/python3.10/site-packages/transformers/utils/hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    386\u001b[0m         path_or_repo_id,\n\u001b[1;32m    387\u001b[0m         filename,\n\u001b[1;32m    388\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    389\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    390\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    391\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    392\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    393\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    394\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    395\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    396\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    397\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    399\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    112\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'artifacts/model_trainer/tokenizer'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model_evaluation\u001b[39m.\u001b[39mevaluate()\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model_evaluation_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_model_evaluation_config()\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model_evaluation \u001b[39m=\u001b[39m ModelEvaluation(config\u001b[39m=\u001b[39mmodel_evaluation_config)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model_evaluation\u001b[39m.\u001b[39;49mevaluate()\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mtokenizer_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     model_pegasus \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmodel_path)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/research/05_model_evaluation.ipynb#W5sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     dataset_samsum_pt \u001b[39m=\u001b[39m load_from_disk(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_path)\n",
      "File \u001b[0;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/env/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:758\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    757\u001b[0m \u001b[39m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m tokenizer_config \u001b[39m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    760\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tokenizer_config[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/env/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:590\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     token \u001b[39m=\u001b[39m use_auth_token\n\u001b[1;32m    589\u001b[0m commit_hash \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 590\u001b[0m resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    591\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    592\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m    593\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    594\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    595\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    596\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    597\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    598\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    599\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    600\u001b[0m     subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    601\u001b[0m     _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    602\u001b[0m     _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    603\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    604\u001b[0m )\n\u001b[1;32m    605\u001b[0m \u001b[39mif\u001b[39;00m resolved_config_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Text_summarzer_project/env/lib/python3.10/site-packages/transformers/utils/hub.py:450\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load \u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    449\u001b[0m \u001b[39mexcept\u001b[39;00m HFValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncorrect path_or_model_id: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: 'artifacts/model_trainer/tokenizer'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_evaluation.evaluate()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
